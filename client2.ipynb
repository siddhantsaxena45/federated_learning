{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48520948-1922-4f81-8ddb-e7580d125687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\flower_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10240 files belonging to 4 classes.\n",
      "Found 1283 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter client ID (0 or 1):  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 class weights computed.\n",
      "âœ… CNN model created.\n",
      "ðŸš€ Starting client 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message dade3672-ee26-4e1a-adee-9357c347c574\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message ec045fe2-16d8-4390-a3bf-c55550687f30\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 521f38e1-d7a0-4317-b41f-bbe09ec86c04\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message a2ce51b0-421d-43e2-96f7-efcff2ced5bd\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 7e3a454c-2a2b-4430-955a-1a079062f9e7\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 37541a79-ece5-44e0-bbbd-393261c721ef\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: reconnect message e6334d3d-4b3e-45dc-9542-c5d93ff1cd66\n",
      "\u001b[92mINFO \u001b[0m:      Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -------------------------\n",
    "#   Load and preprocess data\n",
    "# -------------------------\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"AlzheimerDataset/train\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"AlzheimerDataset/test\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Normalize images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Partition data across clients\n",
    "def partition_dataset(dataset, client_id, num_clients=2):\n",
    "    return dataset.shard(num_shards=num_clients, index=client_id)\n",
    "\n",
    "client_id = int(input(\"Enter client ID (0 or 1): \"))\n",
    "\n",
    "# Each client gets its own unique training and testing data partition\n",
    "train_client_ds = partition_dataset(train_ds, client_id, num_clients=2)\n",
    "test_client_ds = partition_dataset(test_ds, client_id, num_clients=2) # âœ… PARTITION THE TEST DATA\n",
    "\n",
    "# Memory-safe class weight calculation\n",
    "y_train_list = []\n",
    "for _, batch_y in train_client_ds:\n",
    "    y_train_list.append(batch_y.numpy())\n",
    "y_train_client = np.concatenate(y_train_list)\n",
    "\n",
    "classes = np.unique(y_train_client)\n",
    "class_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_client)\n",
    "class_weights = dict(zip(classes, class_weights))\n",
    "print(f\"Client {client_id} class weights computed.\")\n",
    "\n",
    "# -------------------------\n",
    "#   Define CNN model\n",
    "# -------------------------\n",
    "def create_cnn_model():\n",
    "    \"\"\"Creates a memory-efficient CNN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(128, 128, 3)),\n",
    "        layers.Conv2D(16, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model()\n",
    "print(\"âœ… CNN model created.\")\n",
    "\n",
    "# -------------------------\n",
    "#   Flower client class\n",
    "# -------------------------\n",
    "class AlzheimerClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self, config=None):\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        model.fit(train_client_ds, epochs=1, class_weight=class_weights, verbose=0)\n",
    "        return model.get_weights(), len(y_train_client), {}\n",
    "\n",
    "    def evaluate(self, parameters, config=None):\n",
    "        model.set_weights(parameters)\n",
    "        \n",
    "        # âœ… EVALUATE ON THE CLIENT'S PARTITIONED TEST DATA\n",
    "        loss, acc = model.evaluate(test_client_ds, verbose=0)\n",
    "        \n",
    "        y_true, y_pred = [], []\n",
    "        # âœ… PREDICT ON THE CLIENT'S PARTITIONED TEST DATA\n",
    "        for batch_x, batch_y in test_client_ds:\n",
    "            preds = model.predict(batch_x, verbose=0)\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            y_true.extend(batch_y.numpy())\n",
    "            y_pred.extend(preds)\n",
    "        \n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred, labels=classes) # Ensure all classes are represented\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "        \n",
    "        class_acc = {f\"class_{cls}_acc\": report.get(str(cls), {}).get(\"recall\", 0.0) \n",
    "                     for cls in classes}\n",
    "        \n",
    "        metrics = {\"loss\": loss, \"accuracy\": acc}\n",
    "        metrics.update(class_acc)\n",
    "        \n",
    "        cm_flat_list = cm.flatten().tolist()\n",
    "        cm_string = \",\".join(map(str, cm_flat_list))\n",
    "        \n",
    "        metrics[\"confusion_matrix_str\"] = cm_string\n",
    "        metrics[\"num_classes\"] = cm.shape[0]\n",
    "\n",
    "        num_test_examples = len(y_true)\n",
    "        \n",
    "        return loss, num_test_examples, metrics\n",
    "\n",
    "# -------------------------\n",
    "#   Start client\n",
    "# -------------------------\n",
    "print(f\"ðŸš€ Starting client {client_id}...\")\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=AlzheimerClient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca00c7-fb5f-4bd7-acdd-4546b1eab958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
