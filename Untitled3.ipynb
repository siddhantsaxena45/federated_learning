{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139a22ec-c8be-410d-8181-c48b721fc0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10240 files belonging to 4 classes.\n",
      "Found 1283 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter client ID (0 or 1):  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
      "\tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
      "\n",
      "\t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
      "\n",
      "\tTo view all available options, run:\n",
      "\n",
      "\t\t$ flower-supernode --help\n",
      "\n",
      "\tUsing `start_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting client 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: get_parameters message f946b2a7-234c-49fd-a630-7516bbf9fe78\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 742e26ef-1603-4008-94d3-7d789084de23\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message ca753ab9-0380-4165-a209-c82ff24e7d92\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 8103afa8-a548-44d9-9ff4-7b05b9a73ee4\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message b9cb4404-8592-44b9-9b3d-7cd2395375fa\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 4ce50ec4-7bc6-46c2-a5bb-61aae47b81a7\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message feb4a422-798c-41dc-8d91-7e89f43166a4\n",
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: reconnect message af86463e-1c17-4def-b2b5-fc45a5852f41\n",
      "\u001b[92mINFO \u001b[0m:      Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# -------------------------\n",
    "#   Load and preprocess data\n",
    "# -------------------------\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"AlzheimerDataset/train\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"AlzheimerDataset/test\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Normalize images\n",
    "train_ds = train_ds.map(lambda x, y: (x/255.0, y))\n",
    "test_ds = test_ds.map(lambda x, y: (x/255.0, y))\n",
    "\n",
    "# Partition data across clients\n",
    "def partition_dataset(dataset, client_id, num_clients=2):\n",
    "    dataset = dataset.shuffle(10000)\n",
    "    total_size = len(dataset)\n",
    "    part_size = total_size // num_clients\n",
    "    start = client_id * part_size\n",
    "    end = start + part_size\n",
    "    return dataset.skip(start).take(part_size)\n",
    "\n",
    "client_id = int(input(\"Enter client ID (0 or 1): \"))\n",
    "train_client_ds = partition_dataset(train_ds, client_id, num_clients=2)\n",
    "\n",
    "# Convert partitioned dataset to numpy arrays for computing class weights\n",
    "x_train_list, y_train_list = [], []\n",
    "for batch_x, batch_y in train_client_ds:\n",
    "    x_train_list.append(batch_x.numpy())\n",
    "    y_train_list.append(batch_y.numpy())\n",
    "\n",
    "x_train_client = np.concatenate(x_train_list)\n",
    "y_train_client = np.concatenate(y_train_list)\n",
    "\n",
    "# Compute class weights\n",
    "classes = np.unique(y_train_client)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train_client\n",
    ")\n",
    "class_weights = dict(zip(classes, class_weights))\n",
    "\n",
    "# -------------------------\n",
    "#   Define CNN model\n",
    "# -------------------------\n",
    "def create_cnn_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=img_size + (3,)),\n",
    "        layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model()\n",
    "\n",
    "# -------------------------\n",
    "#   Flower client class\n",
    "# -------------------------\n",
    "class AlzheimerClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self, config=None):\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        model.fit(\n",
    "            x_train_client, y_train_client,\n",
    "            epochs=1,\n",
    "            batch_size=32,\n",
    "            class_weight=class_weights,   # âœ… Apply weights\n",
    "            verbose=0\n",
    "        )\n",
    "        return model.get_weights(), len(x_train_client), {}\n",
    "\n",
    "    def evaluate(self, parameters, config=None):\n",
    "        model.set_weights(parameters)\n",
    "\n",
    "        # Evaluate overall loss/accuracy\n",
    "        loss, acc = model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "        # Get predictions for per-class accuracy\n",
    "        y_true, y_pred = [], []\n",
    "        for batch_x, batch_y in test_ds:\n",
    "            preds = model.predict(batch_x, verbose=0)\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            y_true.extend(batch_y.numpy())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Generate per-class metrics\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        # Extract per-class accuracy\n",
    "        class_acc = {f\"class_{cls}_acc\": report[str(cls)][\"recall\"] \n",
    "                     for cls in np.unique(y_true)}\n",
    "\n",
    "        # Merge metrics\n",
    "        metrics = {\"loss\": loss, \"accuracy\": acc}\n",
    "        metrics.update(class_acc)\n",
    "\n",
    "        return loss, len(test_ds), metrics\n",
    "\n",
    "# -------------------------\n",
    "#   Start client\n",
    "# -------------------------\n",
    "print(f\"ðŸš€ Starting client {client_id}\")\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=AlzheimerClient())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd9c67-9734-4353-9e97-3313d4e3c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
